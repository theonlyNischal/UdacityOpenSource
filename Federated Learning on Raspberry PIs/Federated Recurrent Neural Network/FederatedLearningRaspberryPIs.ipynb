{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FederatedLearningRaspberryPIs.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "j9VX3Bnj0ADL",
        "outputId": "8a86d2f5-69dc-49e8-bb3b-5f2f86dad048",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#Install PySyft in Google Colab\n",
        "\n",
        "!pip install tf-encrypted==0.5.6\n",
        "!pip install msgpack==0.6.1\n",
        "\n",
        "! URL=\"https://github.com/openmined/PySyft.git\" && FOLDER=\"PySyft\" && if [ ! -d $FOLDER ]; then git clone -b dev --single-branch $URL; else (cd $FOLDER && git pull $URL && cd ..); fi;\n",
        "\n",
        "!cd PySyft; python setup.py install  > /dev/null\n",
        "\n",
        "import os\n",
        "import sys\n",
        "module_path = os.path.abspath(os.path.join('./PySyft'))\n",
        "if module_path not in sys.path:\n",
        "    sys.path.append(module_path)\n",
        "    \n",
        "!pip install --upgrade --force-reinstall lz4\n",
        "!pip install --upgrade --force-reinstall websocket\n",
        "!pip install --upgrade --force-reinstall websockets\n",
        "!pip install --upgrade --force-reinstall zstd"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tf-encrypted==0.5.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/ce/da9916e7e78f736894b15538b702c0b213fd5d60a7fd6e481d74033a90c0/tf_encrypted-0.5.6-py3-none-manylinux1_x86_64.whl (1.4MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4MB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow<2,>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tf-encrypted==0.5.6) (1.14.0)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tf-encrypted==0.5.6) (1.16.4)\n",
            "Collecting pyyaml>=5.1 (from tf-encrypted==0.5.6)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/e8/b3212641ee2718d556df0f23f78de8303f068fe29cdaa7a91018849582fe/PyYAML-5.1.2.tar.gz (265kB)\n",
            "\u001b[K     |████████████████████████████████| 266kB 42.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted==0.5.6) (1.1.0)\n",
            "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted==0.5.6) (1.14.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted==0.5.6) (1.11.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted==0.5.6) (0.8.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted==0.5.6) (1.12.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted==0.5.6) (1.0.8)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted==0.5.6) (1.15.0)\n",
            "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted==0.5.6) (1.14.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted==0.5.6) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted==0.5.6) (3.7.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted==0.5.6) (0.7.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted==0.5.6) (0.33.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted==0.5.6) (0.1.7)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted==0.5.6) (0.2.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow<2,>=1.12.0->tf-encrypted==0.5.6) (2.8.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow<2,>=1.12.0->tf-encrypted==0.5.6) (41.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow<2,>=1.12.0->tf-encrypted==0.5.6) (3.1.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow<2,>=1.12.0->tf-encrypted==0.5.6) (0.15.5)\n",
            "Building wheels for collected packages: pyyaml\n",
            "  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyyaml: filename=PyYAML-5.1.2-cp36-cp36m-linux_x86_64.whl size=44105 sha256=79e4a6c7aa62a89b06e66fa10f88742f75f14c5ac7d3b90eef5f32a53a873aac\n",
            "  Stored in directory: /root/.cache/pip/wheels/d9/45/dd/65f0b38450c47cf7e5312883deb97d065e030c5cca0a365030\n",
            "Successfully built pyyaml\n",
            "Installing collected packages: pyyaml, tf-encrypted\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed pyyaml-5.1.2 tf-encrypted-0.5.6\n",
            "Collecting msgpack==0.6.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/7e/ae9e91c1bb8d846efafd1f353476e3fd7309778b582d2fb4cea4cc15b9a2/msgpack-0.6.1-cp36-cp36m-manylinux1_x86_64.whl (248kB)\n",
            "\u001b[K     |████████████████████████████████| 256kB 2.8MB/s \n",
            "\u001b[?25hInstalling collected packages: msgpack\n",
            "  Found existing installation: msgpack 0.5.6\n",
            "    Uninstalling msgpack-0.5.6:\n",
            "      Successfully uninstalled msgpack-0.5.6\n",
            "Successfully installed msgpack-0.6.1\n",
            "Cloning into 'PySyft'...\n",
            "remote: Enumerating objects: 10, done.\u001b[K\n",
            "remote: Counting objects: 100% (10/10), done.\u001b[K\n",
            "remote: Compressing objects: 100% (10/10), done.\u001b[K\n",
            "remote: Total 30374 (delta 0), reused 2 (delta 0), pack-reused 30364\u001b[K\n",
            "Receiving objects: 100% (30374/30374), 33.01 MiB | 21.35 MiB/s, done.\n",
            "Resolving deltas: 100% (20363/20363), done.\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "__pycache__.zstd.cpython-36: module references __file__\n",
            "Collecting lz4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0a/c6/96bbb3525a63ebc53ea700cc7d37ab9045542d33b4d262d0f0408ad9bbf2/lz4-2.1.10-cp36-cp36m-manylinux1_x86_64.whl (385kB)\n",
            "\u001b[K     |████████████████████████████████| 389kB 2.8MB/s \n",
            "\u001b[?25hInstalling collected packages: lz4\n",
            "  Found existing installation: lz4 2.1.10\n",
            "    Uninstalling lz4-2.1.10:\n",
            "      Successfully uninstalled lz4-2.1.10\n",
            "Successfully installed lz4-2.1.10\n",
            "Collecting websocket\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f2/6d/a60d620ea575c885510c574909d2e3ed62129b121fa2df00ca1c81024c87/websocket-0.2.1.tar.gz (195kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 2.8MB/s \n",
            "\u001b[?25hCollecting gevent (from websocket)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f2/ca/5b5962361ed832847b6b2f9a2d0452c8c2f29a93baef850bb8ad067c7bf9/gevent-1.4.0-cp36-cp36m-manylinux1_x86_64.whl (5.5MB)\n",
            "\u001b[K     |████████████████████████████████| 5.5MB 41.0MB/s \n",
            "\u001b[?25hCollecting greenlet (from websocket)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bf/45/142141aa47e01a5779f0fa5a53b81f8379ce8f2b1cd13df7d2f1d751ae42/greenlet-0.4.15-cp36-cp36m-manylinux1_x86_64.whl (41kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 20.3MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: websocket\n",
            "  Building wheel for websocket (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for websocket: filename=websocket-0.2.1-cp36-none-any.whl size=192134 sha256=6cca75b1231e71a150822ff9509eca126702cf733a3429c80969ad181b38ab75\n",
            "  Stored in directory: /root/.cache/pip/wheels/35/f7/5c/9e8243838269ea93f05295708519a6e183fa6b515d9ce3b636\n",
            "Successfully built websocket\n",
            "Installing collected packages: greenlet, gevent, websocket\n",
            "  Found existing installation: greenlet 0.4.15\n",
            "    Uninstalling greenlet-0.4.15:\n",
            "      Successfully uninstalled greenlet-0.4.15\n",
            "  Found existing installation: gevent 1.4.0\n",
            "    Uninstalling gevent-1.4.0:\n",
            "      Successfully uninstalled gevent-1.4.0\n",
            "Successfully installed gevent-1.4.0 greenlet-0.4.15 websocket-0.2.1\n",
            "Collecting websockets\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f0/4b/ad228451b1c071c5c52616b7d4298ebcfcac5ae8515ede959db19e4cd56d/websockets-8.0.2-cp36-cp36m-manylinux1_x86_64.whl (72kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 3.1MB/s \n",
            "\u001b[?25hInstalling collected packages: websockets\n",
            "  Found existing installation: websockets 8.0.2\n",
            "    Uninstalling websockets-8.0.2:\n",
            "      Successfully uninstalled websockets-8.0.2\n",
            "Successfully installed websockets-8.0.2\n",
            "Collecting zstd\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/37/6a7ba746ebddbd6cd06de84367515d6bc239acd94fb3e0b1c85788176ca2/zstd-1.4.1.0.tar.gz (454kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 2.9MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: zstd\n",
            "  Building wheel for zstd (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for zstd: filename=zstd-1.4.1.0-cp36-cp36m-linux_x86_64.whl size=1067092 sha256=dc04663f8715949634e33630db6e7a8aaa1a3a325a20d6cb7896601cc9a235f0\n",
            "  Stored in directory: /root/.cache/pip/wheels/66/3f/ee/ac08c81af7c1b24a80c746df669ea3cb37542d27877d66ccf4\n",
            "Successfully built zstd\n",
            "Installing collected packages: zstd\n",
            "  Found existing installation: zstd 1.4.1.0\n",
            "    Uninstalling zstd-1.4.1.0:\n",
            "      Successfully uninstalled zstd-1.4.1.0\n",
            "Successfully installed zstd-1.4.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AZjutp4dJYTM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "a3c0a0f0-3f05-426c-86d1-304b641b6363"
      },
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "import torch\n",
        "from io import open\n",
        "import glob\n",
        "import os\n",
        "import numpy as np\n",
        "import unicodedata\n",
        "import string\n",
        "import random\n",
        "import torch.nn as nn\n",
        "import time\n",
        "import math\n",
        "import syft as sy\n",
        "import pandas as pd\n",
        "import random\n",
        "from syft.frameworks.torch.federated import utils\n",
        "\n",
        "from syft.workers import WebsocketClientWorker\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0818 10:51:05.461451 139663277889408 secure_random.py:26] Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow. Fix this by compiling custom ops. Missing file was '/usr/local/lib/python3.6/dist-packages/tf_encrypted/operations/secure_random/secure_random_module_tf_1.14.0.so'\n",
            "W0818 10:51:05.484668 139663277889408 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tf_encrypted/session.py:26: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PHWeK2dOInPy",
        "outputId": "711f9e88-8dca-4b4a-d611-49e85c5f9bad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        }
      },
      "source": [
        "!wget https://download.pytorch.org/tutorial/data.zip  "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-08-18 10:51:06--  https://download.pytorch.org/tutorial/data.zip\n",
            "Resolving download.pytorch.org (download.pytorch.org)... 13.226.42.89, 13.226.42.64, 13.226.42.10, ...\n",
            "Connecting to download.pytorch.org (download.pytorch.org)|13.226.42.89|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2882130 (2.7M) [application/zip]\n",
            "Saving to: ‘data.zip’\n",
            "\n",
            "\rdata.zip              0%[                    ]       0  --.-KB/s               \rdata.zip             33%[=====>              ] 930.88K  4.54MB/s               \rdata.zip             86%[================>   ]   2.38M  5.92MB/s               \rdata.zip            100%[===================>]   2.75M  6.23MB/s    in 0.4s    \n",
            "\n",
            "2019-08-18 10:51:07 (6.23 MB/s) - ‘data.zip’ saved [2882130/2882130]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VArqRDUbIt37",
        "outputId": "a15b25d6-a6c1-4535-c269-f86c61fcf81f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        }
      },
      "source": [
        "!unzip data.zip"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  data.zip\n",
            "   creating: data/\n",
            "  inflating: data/eng-fra.txt        \n",
            "   creating: data/names/\n",
            "  inflating: data/names/Arabic.txt   \n",
            "  inflating: data/names/Chinese.txt  \n",
            "  inflating: data/names/Czech.txt    \n",
            "  inflating: data/names/Dutch.txt    \n",
            "  inflating: data/names/English.txt  \n",
            "  inflating: data/names/French.txt   \n",
            "  inflating: data/names/German.txt   \n",
            "  inflating: data/names/Greek.txt    \n",
            "  inflating: data/names/Irish.txt    \n",
            "  inflating: data/names/Italian.txt  \n",
            "  inflating: data/names/Japanese.txt  \n",
            "  inflating: data/names/Korean.txt   \n",
            "  inflating: data/names/Polish.txt   \n",
            "  inflating: data/names/Portuguese.txt  \n",
            "  inflating: data/names/Russian.txt  \n",
            "  inflating: data/names/Scottish.txt  \n",
            "  inflating: data/names/Spanish.txt  \n",
            "  inflating: data/names/Vietnamese.txt  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eFyuwgqaI_yB",
        "outputId": "ec97e9d7-5e0a-490d-84f5-b8fd12576f56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "path = '/content/data/names/*.txt'\n",
        "\n",
        "all_letters = string.ascii_letters + \".,;'\"\n",
        "n_letters = len(all_letters)\n",
        "\n",
        "\n",
        "#Load files in the path\n",
        "def findFiles(path):\n",
        "  return glob.glob(path)\n",
        "\n",
        "#Read a file and then split to lines\n",
        "def readLines(filename):\n",
        "  lines =open(filename, encoding='utf-8').read().strip().split('\\n')\n",
        "  return [unicodeToAscii(line) for line in lines]\n",
        "\n",
        "#Convert  string to ASCII format\n",
        "def unicodeToAscii(s):\n",
        "  return ''.join(\n",
        "      c for c in unicodedata.normalize('NFD', s)\n",
        "      if unicodedata.category(c) != 'Mn'\n",
        "      and c in all_letters\n",
        "  )\n",
        "\n",
        "\n",
        "\n",
        "category_lines = {}\n",
        "all_categories = []\n",
        "\n",
        "for filename in findFiles(path):\n",
        "  #print(filename)\n",
        "  category = os.path.splitext(os.path.basename(filename))[0]\n",
        "  all_categories.append(category)\n",
        "  lines = readLines(filename)\n",
        "  category_lines[category] = lines\n",
        "  \n",
        "n_categories = len(all_categories)\n",
        "\n",
        "#for names in glob.glob(path):\n",
        "  #print(names)\n",
        "  \n",
        " \n",
        "print(\"Number of categories: \" + \"\\n\" + str(n_categories))\n",
        "print(\"\\n\" + \"All categories: \")\n",
        "print(*all_categories, sep = \"\\n\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of categories: \n",
            "18\n",
            "\n",
            "All categories: \n",
            "Italian\n",
            "Irish\n",
            "Dutch\n",
            "Scottish\n",
            "Vietnamese\n",
            "Portuguese\n",
            "Japanese\n",
            "French\n",
            "Chinese\n",
            "Russian\n",
            "Polish\n",
            "German\n",
            "Korean\n",
            "Greek\n",
            "English\n",
            "Arabic\n",
            "Czech\n",
            "Spanish\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1dfyi8UZMQnz"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CA4do6B9YvLE",
        "outputId": "b9bdaedc-aa49-457c-8731-f8f9f996525a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "print(*category_lines['Polish'][:6], sep = \"\\n\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Adamczak\n",
            "Adamczyk\n",
            "Andrysiak\n",
            "Auttenberg\n",
            "Bartosz\n",
            "Bernard\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HTRGMBHov73y",
        "colab": {}
      },
      "source": [
        "class LanguageDataset(Dataset):\n",
        "  # Constructor\n",
        "  def __init__(self, text, labels, transform=None):\n",
        "    self.data = text\n",
        "    self.targets = labels # categories\n",
        "    #self.to_torchtensor()\n",
        "    self.transform = transform\n",
        "    \n",
        "  def to_torchtensor(self):\n",
        "    self.data = torch.from_numpy(self.text, requires_grad=True)\n",
        "    self.labels = torch.from_numpy(self.targets, requires_grad=True)\n",
        "  \n",
        "  # Returns length of dataset/batches\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "  \n",
        "  # Returns data and target[torch tensor ]\n",
        "  def __getitem__(self, idx):\n",
        "    sample = self.data[idx]\n",
        "    target = self.targets[idx]\n",
        "    \n",
        "    if self.transform:\n",
        "      sample = self.transform(sample)\n",
        "      \n",
        "    return sample, target\n",
        "    \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ia7UiNvbAlMU",
        "colab": {}
      },
      "source": [
        "# Arguments for the program\n",
        "class Arguments():\n",
        "  def __init__(self):\n",
        "    self.batch_size = 1\n",
        "    self.learning_rate = 0.005\n",
        "    self.epochs = 10000\n",
        "    self.federate_after_n_batches =15000\n",
        "    self.seed = 1\n",
        "    self.print_every = 200\n",
        "    self.plot_every = 100\n",
        "    self.use_cuda = False\n",
        "    \n",
        "args = Arguments()\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YaHCIZtGDvEO",
        "outputId": "6141d352-3d67-452d-b680-a875f8c3bf3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%%latex\n",
        "\n",
        "\\begin{split}\n",
        "names\\_list = [d_1,...d_n]  \\\\\n",
        "\n",
        "category\\_list = [c_1,...c_n]\n",
        "\\end{split}"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/latex": "\n\\begin{split}\nnames\\_list = [d_1,...d_n]  \\\\\n\ncategory\\_list = [c_1,...c_n]\n\\end{split}",
            "text/plain": [
              "<IPython.core.display.Latex object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Qtr-6GH2GRMR",
        "outputId": "adea30f0-584e-4317-f44d-a34fcae7f61b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "names_list = []\n",
        "category_list = []\n",
        "\n",
        "for nation, names in category_lines.items():\n",
        "  for name in names:\n",
        "    names_list.append(name)\n",
        "    category_list.append(nation)\n",
        "    \n",
        "print(*names_list[:5], sep = \"\\n\")\n",
        "print(*category_list[:5], sep = \"\\n\")\n",
        "print(\"\\n\")\n",
        "print(\"Data points loaded: \" + str(len(names_list)))\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Abandonato\n",
            "Abatangelo\n",
            "Abatantuono\n",
            "Abate\n",
            "Abategiovanni\n",
            "Italian\n",
            "Italian\n",
            "Italian\n",
            "Italian\n",
            "Italian\n",
            "\n",
            "\n",
            "Data points loaded: 20074\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BKJZuuFzMw6H",
        "outputId": "69024b95-3f21-472c-951b-6195c64e753f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "# An integer to every category\n",
        "categories_numerical = pd.factorize(category_list)[0]\n",
        "\n",
        "# Categories with tensor\n",
        "category_tensor = torch.tensor(np.array(categories_numerical), dtype=torch.long)\n",
        "\n",
        "categories_numpy = np.array(category_tensor)\n",
        "\n",
        "print(names_list[100:120])\n",
        "print(categories_numpy[100:120])\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Allegro', 'Alo', 'Aloia', 'Aloisi', 'Altamura', 'Altimari', 'Altoviti', 'Alunni', 'Amadei', 'Amadori', 'Amalberti', 'Amantea', 'Amato', 'Amatore', 'Ambrogi', 'Ambrosi', 'Amello', 'Amerighi', 'Amoretto', 'Angioli']\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MIe6sXJo7Sdz"
      },
      "source": [
        "We will turn every character in each input string into a vector, with a 1 marking that particular character present. <br>\n",
        "A word will just be a vector of character vectors and our RNN will process every character vector in the word.<br>\n",
        "This technique is called word embedding."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fH3mARx7Q7y2",
        "colab": {}
      },
      "source": [
        "# This returns the index of a letter given\n",
        "def letterToIndex(letter):\n",
        "    return all_letters.find(letter)\n",
        "    \n",
        "\n",
        "# Turn a line into a <line_length x 1 x n_letters>\n",
        "def lineToTensor(line):\n",
        "    tensor = torch.zeros(len(line), 1, n_letters)\n",
        "    for li, letter in enumerate(line):\n",
        "        tensor[li][0][letterToIndex(letter)] = 1\n",
        "    return tensor    \n",
        "    \n",
        "    \n",
        "# Turn a list of strings into a list of tensors\n",
        "def list_strings_to_list_tensors(names_list):\n",
        "    lines_tensors = []\n",
        "    for index, line in enumerate(names_list):\n",
        "        lineTensor = lineToTensor(line)\n",
        "        lineNumpy = lineTensor.numpy()\n",
        "        lines_tensors.append(lineNumpy)\n",
        "        \n",
        "    return(lines_tensors)\n",
        "\n",
        "lines_tensors = list_strings_to_list_tensors(names_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aN5qo2w3TwRd",
        "outputId": "01cabafb-72cf-4242-bf1e-9ebf099d9b13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        }
      },
      "source": [
        "# Testing the functions work\n",
        "print(names_list[0])\n",
        "print(lines_tensors[0])\n",
        "print(lines_tensors[0].shape)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Abandonato\n",
            "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "\n",
            " [[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "\n",
            " [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "\n",
            " [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n",
            "(10, 1, 56)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rAJ6cy5dQ7wR",
        "colab": {}
      },
      "source": [
        "# Identify the longest word in the dataset as all tensors need to have the same\n",
        "# shape \n",
        "\n",
        "max_line_size = max(len(x) for x in lines_tensors)\n",
        "\n",
        "# Turn a line into a <line_length x 1 x n_letters>\n",
        "def lineToTensorFillEmpty(line, max_line_size):\n",
        "    tensor = torch.zeros(max_line_size, 1, n_letters)\n",
        "    for li, letter in enumerate(line):\n",
        "        tensor[li][0][letterToIndex(letter)] = 1\n",
        "        \n",
        "    # If there is no character, a vector with (0,0,.... ,0) will be placed\n",
        "    return tensor\n",
        "\n",
        "# Turn a list of strings into a list of tensors using previous function\n",
        "def list_strings_to_list_tensors_fill_empty(names_list):\n",
        "    lines_tensors = []\n",
        "    for index, line in enumerate(names_list):\n",
        "        lineTensor = lineToTensorFillEmpty(line, max_line_size)\n",
        "        lines_tensors.append(lineTensor)\n",
        "    return(lines_tensors)\n",
        "\n",
        "lines_tensors = list_strings_to_list_tensors_fill_empty(names_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kabCi_VU7a_n",
        "outputId": "bb3a9506-7095-4f69-edb6-f4810869cc64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Tensor shape check\n",
        "print(lines_tensors[0].shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([19, 1, 56])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "h1c69hd57de_",
        "outputId": "6e8e6ba5-3b3f-4aef-fc8c-f73d8afd2ded",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Create numpy array with all word embeddings\n",
        "array_lines_tensors = np.stack(lines_tensors)\n",
        "array_lines_proper_dimension = np.squeeze(array_lines_tensors, axis=2)\n",
        "\n",
        "# Check array dimension\n",
        "print(array_lines_proper_dimension.shape)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(20074, 19, 56)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HVnv7Zkr7fEj",
        "outputId": "15a9a9e8-dbfc-4374-e60f-95cea1b9e39b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 57
        }
      },
      "source": [
        "def find_start_index_per_category(category_list):\n",
        "    categories_start_index = {}\n",
        "    \n",
        "    #Initialize every category with an empty list\n",
        "    for category in all_categories:\n",
        "        categories_start_index[category] = []\n",
        "    \n",
        "    #Insert the start index of each category into the dictionary categories_start_index\n",
        "    #Example: \"Italian\" --> 203\n",
        "    #         \"Spanish\" --> 19776\n",
        "    last_category = None\n",
        "    i = 0\n",
        "    for name in names_list:\n",
        "        cur_category = category_list[i]\n",
        "        if(cur_category != last_category):\n",
        "            categories_start_index[cur_category] = i\n",
        "            last_category = cur_category\n",
        "        \n",
        "        i = i + 1\n",
        "        \n",
        "    return(categories_start_index)\n",
        "\n",
        "categories_start_index = find_start_index_per_category(category_list)\n",
        "\n",
        "print(categories_start_index)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'Italian': 0, 'Irish': 709, 'Dutch': 941, 'Scottish': 1238, 'Vietnamese': 1338, 'Portuguese': 1411, 'Japanese': 1485, 'French': 2476, 'Chinese': 2753, 'Russian': 3021, 'Polish': 12429, 'German': 12568, 'Korean': 13292, 'Greek': 13386, 'English': 13589, 'Arabic': 17257, 'Czech': 19257, 'Spanish': 19776}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "S4cvPiLB7g2L",
        "colab": {}
      },
      "source": [
        "def randomChoice(l):\n",
        "    rand_value = random.randint(0, len(l) - 1)\n",
        "    return l[rand_value], rand_value\n",
        "\n",
        "\n",
        "def randomTrainingIndex():\n",
        "    category, rand_cat_index = randomChoice(all_categories) #cat = category, it's not a random animal\n",
        "    #rand_line_index is a relative index for a data point within the random category rand_cat_index\n",
        "    line, rand_line_index = randomChoice(category_lines[category])\n",
        "    category_start_index = categories_start_index[category]\n",
        "    absolute_index = category_start_index + rand_line_index\n",
        "    return(absolute_index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uMP1NjRz7ibu",
        "outputId": "e15e11ee-354d-46bb-ab28-9864f2e0981f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "#Two hidden layers, based on simple linear layers\n",
        "\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(RNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
        "        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        combined = torch.cat((input, hidden), 1)\n",
        "        hidden = self.i2h(combined)\n",
        "        output = self.i2o(combined)\n",
        "        output = self.softmax(output)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, self.hidden_size)\n",
        "\n",
        "#Let's instantiate the neural network already:\n",
        "n_hidden = 128\n",
        "#Instantiate RNN\n",
        "\n",
        "device = torch.device(\"cuda\" if args.use_cuda else \"cpu\")\n",
        "model = RNN(n_letters, n_hidden, n_categories).to(device)\n",
        "#The final softmax layer will produce a probability for each one of our 18 categories\n",
        "print(model)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RNN(\n",
            "  (i2h): Linear(in_features=184, out_features=128, bias=True)\n",
            "  (i2o): Linear(in_features=184, out_features=18, bias=True)\n",
            "  (softmax): LogSoftmax()\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pbnoVIjf7ksO",
        "colab": {}
      },
      "source": [
        "# Specify remote workers's location\n",
        "\n",
        "hook = sy.TorchHook(torch)  # Hook PyTorch\n",
        "\n",
        "# Uncomment this with the ip of each raspberry pi worker if you're using the\n",
        "# raspberry pi and comment the block of code beneath this\n",
        "\n",
        "# kwargs_websocket_alice = {\"host\": \"ip_alice\", \"hook\": hook}\n",
        "# alice = WebsocketClientWorker(id=\"alice\", port=8777, **kwargs_websocket_alice)\n",
        "# kwargs_websocket_bob = {\"host\": \"ip_bob\", \"hook\": hook}\n",
        "# bob = WebsocketClientWorker(id=\"bob\", port=8778, **kwargs_websocket_bob)\n",
        "\n",
        "alice = sy.VirtualWorker(hook, id=\"alice\")  \n",
        "bob = sy.VirtualWorker(hook, id=\"bob\")  \n",
        "\n",
        "workers_virtual = [alice, bob]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LoF12vyL7mYu",
        "colab": {}
      },
      "source": [
        "# array_lines_proper_dimension = our data points(X)\n",
        "# categories_numpy = our labels (Y)\n",
        "langDataset = LanguageDataset(array_lines_proper_dimension, categories_numpy)\n",
        "\n",
        "#assign the data points and the corresponding categories to workers.\n",
        "federated_train_loader = sy.FederatedDataLoader(\n",
        "    langDataset.federate(workers_virtual),\n",
        "    batch_size=args.batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Yz3TOccO7p3T"
      },
      "source": [
        "# Model Training\n",
        "Now the data is processed, we'll start to train our RNN!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2kac977c7nzA",
        "colab": {}
      },
      "source": [
        "# Gives the category that corresponds to maximum predicted class probability\n",
        "def categoryFromOutput(output):\n",
        "    top_n, top_i = output.topk(1)\n",
        "    category_i = top_i[0].item()\n",
        "    return all_categories[category_i], category_i\n",
        "\n",
        "# Gives the amount of time passed since \"since\"\n",
        "def timeSince(since):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "# Federated averaging\n",
        "def fed_avg_every_n_iters(model_pointers, iter, federate_after_n_batches):\n",
        "        models_local = {}\n",
        "        \n",
        "        if(iter % args.federate_after_n_batches == 0):\n",
        "            for worker_name, model_pointer in model_pointers.items():\n",
        "                # Assign model to the worker\n",
        "                models_local[worker_name] = model_pointer.copy().get()\n",
        "            model_avg = utils.federated_avg(models_local)\n",
        "           \n",
        "            for worker in workers_virtual:\n",
        "                model_copied_avg = model_avg.copy()\n",
        "                model_ptr = model_copied_avg.send(worker) \n",
        "                model_pointers[worker.id] = model_ptr\n",
        "                \n",
        "        return(model_pointers)     \n",
        "\n",
        "def fw_bw_pass_model(model_pointers, line_single, category_single):\n",
        "  \n",
        "    # Get the right initialized model\n",
        "    model_ptr = model_pointers[line_single.location.id]   \n",
        "    line_reshaped = line_single.reshape(max_line_size, 1, len(all_letters))\n",
        "    line_reshaped, category_single = line_reshaped.to(device), category_single.to(device)\n",
        "    \n",
        "    # Initialize hidden layer\n",
        "    hidden_init = model_ptr.initHidden() \n",
        "    \n",
        "    # And now zero the gradient\n",
        "    model_ptr.zero_grad()\n",
        "    hidden_ptr = hidden_init.send(line_single.location)\n",
        "    amount_lines_non_zero = len(torch.nonzero(line_reshaped.copy().get()))\n",
        "    \n",
        "    # Forward passes\n",
        "    for i in range(amount_lines_non_zero): \n",
        "        output, hidden_ptr = model_ptr(line_reshaped[i], hidden_ptr) \n",
        "    criterion = nn.NLLLoss()   \n",
        "    loss = criterion(output, category_single) \n",
        "    loss.backward()\n",
        "    \n",
        "    model_got = model_ptr.get() \n",
        "    \n",
        "    # Update model's weights \n",
        "    for param in model_got.parameters():\n",
        "        param.data.add_(-args.learning_rate, param.grad.data)\n",
        "        \n",
        "        \n",
        "    # Send the model\n",
        "    model_sent = model_got.send(line_single.location.id)\n",
        "    model_pointers[line_single.location.id] = model_sent\n",
        "    \n",
        "    return(model_pointers, loss, output)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zVAcC1Xl7vDW",
        "colab": {}
      },
      "source": [
        "# Training function\n",
        "def train_RNN(n_iters, print_every, plot_every, federate_after_n_batches, list_federated_train_loader):\n",
        "    current_loss = 0\n",
        "    all_losses = []    \n",
        "    \n",
        "    model_pointers = {}\n",
        "    \n",
        "    # Send the initialized model to every single worker just before training\n",
        "    for worker in workers_virtual:\n",
        "        model_copied = model.copy()\n",
        "        model_ptr = model_copied.send(worker) \n",
        "        model_pointers[worker.id] = model_ptr\n",
        "\n",
        "    # Extract a random element from the list and perform training on it\n",
        "    for iter in range(1, n_iters + 1):        \n",
        "        random_index = randomTrainingIndex()\n",
        "        line_single, category_single = list_federated_train_loader[random_index]\n",
        "        line_name = names_list[random_index]\n",
        "        model_pointers, loss, output = fw_bw_pass_model(model_pointers, line_single, category_single)\n",
        "        \n",
        "        # Update theloss\n",
        "        loss_got = loss.get().item() \n",
        "        current_loss += loss_got\n",
        "        \n",
        "        if iter % plot_every == 0:\n",
        "            all_losses.append(current_loss / plot_every)\n",
        "            current_loss = 0\n",
        "             \n",
        "        # Print information on training\n",
        "        # The name, guessed category, correct/incorrect and actual category\n",
        "        if(iter % print_every == 0):\n",
        "            output_got = output.get()\n",
        "            guess, guess_i = categoryFromOutput(output_got)\n",
        "            category = all_categories[category_single.copy().get().item()]\n",
        "            correct = '✓' if guess == category else '✗ (%s)' % category\n",
        "            print('%d %d%% (%s) %.4f %s / %s %s' % (iter, iter / n_iters * 100, \n",
        "                                                    timeSince(start), \n",
        "                                                    loss_got, \n",
        "                                                    line_name, guess, correct))\n",
        "            \n",
        "            \n",
        "    return(all_losses, model_pointers)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xYOR9rb67yfJ"
      },
      "source": [
        "## Start the training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gCV84KP07xJY",
        "outputId": "19e63a9d-185d-4c4d-bd38-022cd4149f5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        }
      },
      "source": [
        "# Turn the data points and categories into a list\n",
        "list_federated_train_loader = list(federated_train_loader)\n",
        "\n",
        "# Start the training\n",
        "start = time.time()\n",
        "all_losses, model_pointers = train_RNN(args.epochs, args.print_every, \n",
        "                                       args.plot_every, \n",
        "                                       args.federate_after_n_batches, \n",
        "                                       list_federated_train_loader)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "200 2% (0m 10s) 2.8972 Tanzer / Greek ✗ (German)\n",
            "400 4% (0m 19s) 2.8472 Oleastro / Greek ✗ (Spanish)\n",
            "600 6% (0m 28s) 2.7411 Imaizumi / Chinese ✗ (Japanese)\n",
            "800 8% (0m 34s) 2.7128 Stewart / Japanese ✗ (Scottish)\n",
            "1000 10% (0m 39s) 2.6275 an / Chinese ✗ (Vietnamese)\n",
            "1200 12% (0m 44s) 2.6013 Macon / Chinese ✗ (French)\n",
            "1400 14% (0m 48s) 2.4859 Gu / English ✗ (Korean)\n",
            "1600 16% (0m 53s) 2.8049 Olivier / Russian ✗ (French)\n",
            "1800 18% (0m 58s) 2.7870 Duong / Irish ✗ (Vietnamese)\n",
            "2000 20% (1m 3s) 1.9395 Belrose / Italian ✗ (French)\n",
            "2200 22% (1m 8s) 2.1864 Garcia / Japanese ✗ (Portuguese)\n",
            "2400 24% (1m 13s) 1.6652 Obando / Spanish ✓\n",
            "2600 26% (1m 18s) 2.5270 Kazmier / German ✗ (Czech)\n",
            "2800 28% (1m 23s) 4.4912 Zhdanov / Czech ✗ (Russian)\n",
            "3000 30% (1m 28s) 2.0625 Benetton / Portuguese ✗ (Italian)\n",
            "3200 32% (1m 33s) 2.9936 Daele / French ✗ (Dutch)\n",
            "3400 34% (1m 38s) 2.0957 Tsai / Polish ✗ (Korean)\n",
            "3600 36% (1m 42s) 1.9032 Ra / Korean ✓\n",
            "3800 38% (1m 47s) 2.0425 Khoury / Czech ✗ (Arabic)\n",
            "4000 40% (1m 52s) 2.1126 Wright / Japanese ✗ (Scottish)\n",
            "4200 42% (1m 57s) 1.2525 Wang / Korean ✓\n",
            "4400 44% (2m 2s) 2.0513 Voltolini / Russian ✗ (Italian)\n",
            "4600 46% (2m 7s) 1.8831 Fremut / English ✗ (Czech)\n",
            "4800 48% (2m 12s) 1.9730 Rademaker / Russian ✗ (Dutch)\n",
            "5000 50% (2m 17s) 1.9807 Tokudome / Scottish ✗ (Japanese)\n",
            "5200 52% (2m 21s) 2.3107 David / Scottish ✗ (French)\n",
            "5400 54% (2m 26s) 1.1050 Sui / Chinese ✓\n",
            "5600 56% (2m 31s) 2.2416 Watt / Vietnamese ✗ (Scottish)\n",
            "5800 57% (2m 36s) 1.8862 Ferreira / Dutch ✗ (Portuguese)\n",
            "6000 60% (2m 41s) 3.2141 Hay / Chinese ✗ (Scottish)\n",
            "6200 62% (2m 46s) 1.7806 Ghanem / German ✗ (Arabic)\n",
            "6400 64% (2m 50s) 2.3633 Sayegh / German ✗ (Arabic)\n",
            "6600 66% (2m 55s) 1.9683 Beauchene / Italian ✗ (French)\n",
            "6800 68% (3m 0s) 2.3649 Defelice / Russian ✗ (Italian)\n",
            "7000 70% (3m 5s) 2.0098 Baumbach / Greek ✗ (German)\n",
            "7200 72% (3m 10s) 1.7985 Michael / French ✗ (Irish)\n",
            "7400 74% (3m 15s) 1.0206 Lam / Chinese ✗ (Vietnamese)\n",
            "7600 76% (3m 20s) 1.6087 Irwin / English ✓\n",
            "7800 78% (3m 25s) 1.9498 Wiegand / English ✗ (German)\n",
            "8000 80% (3m 29s) 1.1513 Belyavin / Russian ✓\n",
            "8200 82% (3m 34s) 1.6139 Subertova / Spanish ✗ (Czech)\n",
            "8400 84% (3m 39s) 2.3463 Bill / Arabic ✗ (English)\n",
            "8600 86% (3m 44s) 1.5001 Kunik / Czech ✓\n",
            "8800 88% (3m 49s) 0.6737 Law / Chinese ✓\n",
            "9000 90% (3m 54s) 0.8904 Guan / Chinese ✓\n",
            "9200 92% (3m 58s) 3.1176 Rhys / Vietnamese ✗ (Irish)\n",
            "9400 94% (4m 3s) 1.1845 Gomes / Portuguese ✓\n",
            "9600 96% (4m 8s) 1.2769 Trinh / Vietnamese ✓\n",
            "9800 98% (4m 13s) 1.5945 Granger / Dutch ✗ (French)\n",
            "10000 100% (4m 18s) 2.2911 Carey / Portuguese ✗ (Irish)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nQzOB4Vw71rc",
        "outputId": "c22eae6f-5178-4c5d-989a-84724e45b6c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "# Plot the loss we got during the training procedure\n",
        "plt.figure()\n",
        "plt.title(\"Loss over time training\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.xlabel('Epochs (100s)')\n",
        "plt.plot(all_losses)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f05551f9f60>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\njDFe/x+KVCHBV+KE5wAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djy1nPcOVyMB",
        "colab_type": "text"
      },
      "source": [
        "## Predict!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQTAcd3vVyMC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(model, input_line, all_categories, worker, n_predictions=3):\n",
        "    \"\"\" \n",
        "    Uses :attr:`model` to predict top :attr:`n_predictions` categories \n",
        "    from :attr:`all_categories` for :attr:`input_line` using :attr:`worker`\n",
        "  \n",
        "    Parameters: \n",
        "        model (Module): model to be used for the prediction\n",
        "        input_line (str): input to the model\n",
        "        all_categories (list): list of all categories for the prediction\n",
        "        worker(BaseWorker): worker where the prediction will be performed\n",
        "        n_predictions(int): number of top predictions to return\n",
        "  \n",
        "    Returns: \n",
        "        list of tuples (value, category) sorted from max value to min\n",
        "  \n",
        "    \"\"\"\n",
        "    \n",
        "    # copy the model to the worker only if is not already there\n",
        "    if model.location.id != worker.id:\n",
        "        model = model.copy().get()\n",
        "        model_remote = model.send(worker)\n",
        "    else:\n",
        "        model_remote = model\n",
        "    \n",
        "    # convert the input_line to a tensor and send it to the worker\n",
        "    line_tensor = lineToTensor(input_line)\n",
        "    line_remote = line_tensor.copy().send(worker)\n",
        "\n",
        "    # init the hidden layer\n",
        "    hidden = model_remote.initHidden()\n",
        "    hidden_remote = hidden.copy().send(worker)\n",
        "        \n",
        "    # get a result from the model\n",
        "    with torch.no_grad():\n",
        "        for i in range(line_remote.shape[0]):\n",
        "            output, hidden_remote = model_remote(line_remote[i], hidden_remote)\n",
        "    \n",
        "    # get top N categories\n",
        "    topv, topi = output.copy().get().topk(n_predictions, 1, True)\n",
        "\n",
        "    # construct list of (value, category) tuples\n",
        "    predictions = []\n",
        "    for i in range(n_predictions):\n",
        "        value = topv[0][i].item()\n",
        "        category_index = topi[0][i].item()\n",
        "        #print('(%.2f) %s' % (value, all_categories[category_index]))\n",
        "        predictions.append([value, all_categories[category_index]])\n",
        "        \n",
        "    return predictions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APptiMNfVyMD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b695744e-def5-4d37-93b4-6ffd9e759720"
      },
      "source": [
        "print(predict(model_pointers[\"alice\"], \"Qing\", all_categories,  alice) )"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-0.7299680709838867, 'Vietnamese'], [-1.0105748176574707, 'Chinese'], [-3.4629745483398438, 'Scottish']]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}